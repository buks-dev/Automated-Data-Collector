# Automated Data Collector

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![PyQt5](https://img.shields.io/badge/PyQt5-5.15%2B-yellow)](https://riverbankcomputing.com/software/pyqt/intro)
[![Selenium](https://img.shields.io/badge/Selenium-4.0%2B-red)](https://www.selenium.dev/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green)](LICENSE)

A powerful, user-friendly desktop application built with Python and PyQt5 for automating data collection from the web. Designed for efficiency, it leverages Selenium for browser automation, BeautifulSoup for parsing, and Pandas for data handlingâ€”making it ideal for researchers, marketers, or anyone needing to scrape and process structured data at scale.

## ğŸš€ Features

- **Intuitive GUI**: Clean PyQt5-based interface with main window and customizable dialogs for easy configuration and monitoring.
- **Robust Web Scraping**: Selenium-powered browser automation with support for dynamic content, combined with BeautifulSoup for efficient HTML parsing.
- **Data Processing Pipeline**: Built-in tools for extracting, cleaning, and transforming data using Pandas; includes phone number validation and formatting.
- **Modular Design**: Extensible architecture with separate modules for UI, scraping logic, network utilities, and data models.
- **Resource Management**: Automatic webdriver handling via Webdriver Manager; no manual driver downloads required.
- **Export Capabilities**: Seamlessly save processed data to CSV, Excel, or JSON formats.
- **Error Handling & Logging**: Comprehensive logging and user-friendly error dialogs for smooth operation.

## ğŸ“‹ Prerequisites

- Python 3.8 or higher
- A modern web browser (Chrome recommended for Selenium)

## ğŸ›  Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/buks-dev/Automated-Data-Collector.git
   cd Automated-Data-Collector
   ```

2. Install the required dependencies:
   ```bash
   pip install PyQt5 selenium beautifulsoup4 requests pandas webdriver-manager phonenumbers
   ```

3. (Optional) Set up a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

## ğŸš€ Quick Start

Run the application:
```bash
python data_collector/main.py
```

This launches the main window where you can:
- Configure scraping targets via the settings dialog.
- Start data collection sessions.
- Monitor progress and view extracted data in real-time.
- Export results.

For detailed usage, refer to the [User Guide](docs/USER_GUIDE.md) (coming soon).

## ğŸ— Project Structure

```
data_collector/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ main.py                          # Entry point
â”œâ”€â”€ config.py                        # Configuration constants
â”œâ”€â”€ models/                          # Data models
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ ui/                              # Application settings
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main_window.py               # Main application window
â”‚   â””â”€â”€ dialogs.py                   # Settings and other dialogs
â”œâ”€â”€ web_scraping/                    # Web scraping logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ core/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ utils/               # Data collection logic
â”‚   â”‚           â”œâ”€â”€ __init__.py
â”‚   â”‚           â””â”€â”€ browser.py       # Browser operations
â”‚   â””â”€â”€ network/                     # Network utilities
â”‚       â”œâ”€â”€ data.py                  # Data extraction
â”‚       â””â”€â”€ process.py               # Data processing
â””â”€â”€ resources/
    â”œâ”€â”€ icons/
    â””â”€â”€ styles/
```

## ğŸ”§ Customization & Extension

- **Add New Scrapers**: Extend the `web_scraping/components/core/utils` module to define custom extraction logic.
- **UI Tweaks**: Modify styles in `resources/styles/` or add widgets in `ui/dialogs.py`.
- **Data Models**: Update `models/` for new data schemas.

## ğŸ¤ Contributing

Contributions are welcome! Please fork the repo and submit a pull request. For major changes, please open an issue first.

1. Fork the project.
2. Create your feature branch (`git checkout -b feature/AmazingFeature`).
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`).
4. Push to the branch (`git push origin feature/AmazingFeature`).
5. Open a Pull Request.

See [CONTRIBUTING.md](CONTRIBUTING.md) for details (coming soon).

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Built with love using open-source tools like PyQt5, Selenium, and Pandas.
- Thanks to the community for inspiration and bug reports!

---

**â­ Star this repo if it helps you!**  
**ğŸ› Found a bug? [Open an issue](https://github.com/buks-dev/Automated-Data-Collector/issues).**  
**ğŸ’¡ Feature request? Let us know!**
